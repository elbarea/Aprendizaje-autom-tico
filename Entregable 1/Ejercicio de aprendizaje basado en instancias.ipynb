{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje basado en instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos sobre reconocimiento de vinos está incluido en *Scikit-learn*, se obtiene usando la función `load_wine` incluida en la librería `sklearn.datasets`. Este conjunto de datos contiene 178 ejemplos de distintas variedades de vino, con 13 características y tres clasificaciones posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos es un diccionario con varios campos:\n",
    "* `data`: Es el conjunto de datos, se trata de un array en el que cada componente es un array con las características de cada instancia.\n",
    "* `target`: Es el conjunto de valores de clasificación para cada instancia. Es un array del mismo tamaño que `data`, en el que se indica el valor de clasificación de cada instancia, en el mismo orden en que éstas se encuentran en el array `data`.\n",
    "* `DESCR`: Es una descripción del conjunto de datos.\n",
    "* `target_names`: Es un array con los nombres de cada valor de clasificación.\n",
    "* `feature_names`: Es un array con los nombres de cada característica.\n",
    "\n",
    "Almacenamos los datos en las variables `X_data`, `y_data`, `X_names` e `y_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    wine.data, wine.target, wine.feature_names, wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio consiste en\n",
    "* Definir una función que repita el proceso de entrenamiento incrementando el valor del número de vecinos en el algoritmo **k**-*NN* desde 1 hasta 15, devolviendo el mejor valor obtenido para un modelo en el que se han fijado la distancia a considerar `p` y la ponderación de las clasificaciones `weights`.\n",
    "* Construir dos modelos de decisión (para valores concretos de `p` y `weights`) con el mejor valor de `k` obtenido con la función pedida en el punto 1, a partir del conjunto de datos original sin normalizar.\n",
    "* Construir dos modelos de decisión (para valores concretos de `p` y `weights`) con el mejor valor de `k` obtenido con la función pedida en el punto 1, a partir del conjunto de datos normalizado.\n",
    "* Comparar los rendimientos obtenidos con los cuatro modelos construidos.\n",
    "\n",
    "El **desarrollo tiene que estar razonado**, indicando en cada apartado qué se está haciendo, **demostrando así el conocimiento adquirido en este módulo**. ¿Qué conclusiones puedes sacar de lo aprendido sobre aprendizaje basado en instancias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vamos a dividir el dataset inicial en conjuntos de entrenamiento y de testeo, en este caso utilizando un tercio del conjunto para testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_data,y_data,test_size = 0.33,\n",
    "                   random_state=4861,stratify=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación importamos el algoritmo K-NN y hacemos una comprobación inicial para ver que valor de distancia es más óptimo entre la Euclidea y la Manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors = 5, p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=1,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7457627118644068"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors = 5, p = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6949152542372882"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en este caso que la distancia Manhattan da un mejor resultado, así que la utilizaremos para la primera parte de la actividad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un método que recibe conjuntos de entrenamiento y de testeo y devuelve el mejor valor para K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestK(x_train, y_train, x_test, y_test):\n",
    "    res = 0\n",
    "    for i in range(1,16):\n",
    "        knns = KNeighborsClassifier(n_neighbors = i, p = 1,weights='distance')\n",
    "        knns.fit(x_train, y_train)\n",
    "        score = knns.score(x_test, y_test)\n",
    "        if(score>res):\n",
    "            res = score\n",
    "            res1 = i\n",
    "    return res, res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.864406779661017, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findBestK(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el atributo weights se indica como 'distance' el valor óptimo de k pasa a ser 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos los nuevos modelos con el valor de k obtenido anteriormente y variando p y weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864406779661017"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn21 = KNeighborsClassifier(n_neighbors = 3, p = 1, weights='distance')\n",
    "knn21.fit(X_train, Y_train)\n",
    "knn21.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6779661016949152"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn22 = KNeighborsClassifier(n_neighbors = 3, p = 2)\n",
    "knn22.fit(X_train, Y_train)\n",
    "knn22.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora normalizamos los datos antes de darselos a los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello importamos la clase StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenamos el normalizador con el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho eso normalizamos los conjuntos de utilizando el método transfotm del normalizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_train = normalizador.transform(X_train)\n",
    "Xn_test = normalizador.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ya con los nuevos conjuntos normalizados se los pasamos a los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661016949152542"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn31 = KNeighborsClassifier(n_neighbors = 3, p = 1, weights='distance')\n",
    "knn31.fit(Xn_train, Y_train)\n",
    "knn31.score(Xn_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491525423728814"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn32 = KNeighborsClassifier(n_neighbors = 3, p = 2)\n",
    "knn32.fit(Xn_train, Y_train)\n",
    "knn32.score(Xn_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo 1 tiene un rendimiento de:  0.864406779661017\n",
      "El modelo 2 tiene un rendimiento de:  0.6779661016949152\n",
      "El modelo 3 tiene un rendimiento de:  0.9661016949152542\n",
      "El modelo 4 tiene un rendimiento de:  0.9491525423728814\n"
     ]
    }
   ],
   "source": [
    "print('El modelo 1 tiene un rendimiento de: ', knn21.score(X_test, Y_test))\n",
    "print('El modelo 2 tiene un rendimiento de: ', knn22.score(X_test, Y_test))\n",
    "print('El modelo 3 tiene un rendimiento de: ', knn31.score(Xn_test, Y_test))\n",
    "print('El modelo 4 tiene un rendimiento de: ', knn32.score(Xn_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, el modelo que ha dado un mejor rendimiento se trata del **modelo 3**, que utiliza los **conjuntos normalizados**, la **distancia Manhattan**, el parámetro __weights como _distance___ y **k = 3**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
