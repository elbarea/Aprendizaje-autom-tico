{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos probabilísticos (Ejercicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de Naive Bayes multinomial a la detección de SMS *spam*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se pide reproducir lo realizado en el caso práctico que se ha descrito en los vídeos (análisis de sentimiento en críticas de cine), pero ahora para detectar cuándo un mensaje corto (SMS) es *spam*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos consiste una serie de mensajes SMS (5574 en total), que están clasificados como mensajes basura (*spam*) o mensajes normales (*ham*). Los datos se pueden obtener en el [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). \n",
    "\n",
    "En concreto, descargar el fichero [smsspamcollection.zip](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip), y descomprimirlo para obtener un fichero de texto SMSSpamCollection. En este fichero de texto hay una línea por cada sms, con el formato: *clase* *tabulador* *sms*. Por ejemplo, la primera línea es:\n",
    "\n",
    "`ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...`\n",
    "\n",
    "El fichero debe ser leído convenientemente para poder aplicar la vectorización. Se puede hacer la lectura usando las funciones python de lectura de ficheros, pero se recomienda usar la instrucción `read_table` de la biblioteca `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pandas* es una biblioteca de python muy utilizada para manipular y analizar datos. Si el fichero se lee con la orden `read_table` (se pide averiguar la manera concreta de hacerlo), entonces se obtendrá una tabla (o *Data Frame*), en el que las etiquetas serán una columna y los correspondientes sms otra. Esto permite obtener de manera sencilla la lista de etiquetas o clases, y por otro lado la lista de mensajes, en el mismo orden.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo a clasificar SMSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pide reproducir con estos datos lo realizado en el *notebook* en el que se aplica Naive Bayes Multinomial al análisis de sentimientos de críticas de cine, pero ahora para clasificar un SMS como *spam* o como normal. Esto incluye:\n",
    "\n",
    "* Separación de los textos en entrenamiento y prueba \n",
    "* Vectorización de los textos \n",
    "* Aprendizaje con `MultinomialNB`\n",
    "* Mostrar algunas clasificaciones sobre sms concretos.\n",
    "* Rendimiento sobre entrenamiento y prueba.\n",
    "* Ajuste manual del parámetro de suavizado\n",
    "* Vectorización con `min_df` y `stop_words` \n",
    "\n",
    "**Nota**: este conjunto de datos no es balanceado (la mayoría son *ham*). Por tanto, usar `score` no es muy ilustrativo del rendimiento, ya que un clasificador \"tonto\" que siempre predijera *ham* tendría un rendimiento alto. Por ello, en este caso también se hace necesario usar el método `confusion_matrix` del módulo `metrics`. Se pide también explicar la salida que proporciona dicha métrica.\n",
    "\n",
    "Se pide **comentar adecuadamente cada paso realizado**, relacionándolo con lo visto en la teoría. En particular, se pide mostrar parte de los atributos `class_count_`, `class_log_prior_`, `feature_count_` y `feature_log_prob_`, explicando claramente qué son cada uno de ellos. Explicar también cómo realiza las predicciones el modelo aprendido, tal y como se ha explicado en la teoría.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de los textos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero leemos el archivo de datos con el comando read_table de pandas, como se sugiere en el enunciado. Para ello ejecutamos el métidi pasandole como parámetros el nombre del archivo de datos y, en este caso el parámetro header=None para que no de nombre a las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_table(\"SMSSpamCollection\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora doy los nombres X e Y a las columnas del dataframe para que sea más cómodo trabajar con ellas y creo las variables x e y respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"Y\",\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.get('X')\n",
    "y=df.get('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación importo el método trains_test_split de la librería sklearn para separar los textos en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.33,\n",
    "                   random_state=4861,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733 3733 1839 1839\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(y_train), len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya tengo los conjuntos de entrenamiento y prueba para trabajar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización de los textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vectorizamos las variables x_train y x_test con countVectorizer de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_train = vect.transform(x_train)\n",
    "xf_test = vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos las nuevas variables xf_train y xf_test qu están en forma vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yf_train:\n",
      "<3733x7053 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 49319 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "print(\"yf_train:\\n{}\".format(repr(xf_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje con MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo naives bayes multinomial, que es el que usamos aquí, utiliza el número de veces que las palabras aparecen en los documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenamos un modelo con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinb=MultinomialNB().fit(xf_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestran los atributos del modelo que acabamos de entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_count_:\n",
      "[3233.  500.]\n",
      "class_log_prior_:\n",
      "[-0.1438017  -2.01035938]\n",
      "feature_count_:\n",
      "[[ 0.  0.  1. ...  1.  1.  0.]\n",
      " [ 5. 15.  0. ...  0.  0.  1.]]\n",
      "feature_log_prob_:\n",
      "[[-10.79616159 -10.79616159 -10.10301441 ... -10.10301441 -10.10301441\n",
      "  -10.79616159]\n",
      " [ -8.04841548  -7.06758622  -9.84017495 ...  -9.84017495  -9.84017495\n",
      "   -9.14702777]]\n"
     ]
    }
   ],
   "source": [
    "print(\"class_count_:\\n{}\".format(multinb.class_count_))\n",
    "print(\"class_log_prior_:\\n{}\".format(multinb.class_log_prior_))\n",
    "print(\"feature_count_:\\n{}\".format(multinb.feature_count_))\n",
    "print(\"feature_log_prob_:\\n{}\".format(multinb.feature_log_prob_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `class_count_`: Indica el número de casos que tenemos para cada clasificación. En este caso el conjunto no está balanceado, ya que tenemos muchos mas ejemplos de un caso que del otro.\n",
    "* `class_log_prior_`: Indica la probabilidad de pertenecer a cada clase, suavizada usando el logaritmo.\n",
    "* `feature_count_`: Indica, para cada clase, la cantidad de apariciones de cada palabra.\n",
    "* `feature_log_prob_`: Indica, para cada clase, la probabilidad de que cada palabra aparezca o no en un texto.\n",
    "\n",
    "Este tipo de clasificador predice con la clase a la que se que tiene una mayor probabilidad de pertenecer, utilizando las probabilidades de las palabras que aparecen en el caso que trata de predecir. Dichas probabilidades se peuden ver en `feature_log_prob_`, como se ha explicado arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunos SMS concretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS 24 del conjunto test: \n",
      "\n",
      "Nope. Since ayo travelled, he has forgotten his guy\n",
      "\n",
      "Clasificación verdadera: ham.\n",
      "\n",
      "\n",
      "SMS 247 del conjunto test: \n",
      "\n",
      "Watching tv now. I got new job :)\n",
      "\n",
      "Clasificación verdadera: ham.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SMS 24 del conjunto test: \\n\\n{}\\n\".format(x_test.reset_index(drop=True).loc[24]))\n",
    "print(\"Clasificación verdadera: {}.\\n\\n\".format(y_test.reset_index(drop=True)[24]))\n",
    "\n",
    "print(\"SMS 247 del conjunto test: \\n\\n{}\\n\".format(x_test.reset_index(drop=True)[247]))\n",
    "print(\"Clasificación verdadera: {}.\\n\\n\".format(y_test.reset_index(drop=True)[247]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción del clasificador para SMS 24: ham\n",
      "\n",
      "Predicción del clasificador para SMS 247: ham\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicción del clasificador para SMS 24: {}\\n\".format(multinb.predict(vect.transform([x_test.reset_index(drop=True)[24]]))[0]))\n",
    "\n",
    "print(\"Predicción del clasificador para SMS 247: {}\".format(multinb.predict(vect.transform([x_test.reset_index(drop=True)[247]]))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver como ambos ejemplos han sido clasificados de manera correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendimiento sobre entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de multinb sobre el conjunto de entrenamiento: 0.99\n",
      "Rendimiento de multinb sobre el conjunto de test: 0.99\n"
     ]
    }
   ],
   "source": [
    "print(\"Rendimiento de multinb sobre el conjunto de entrenamiento: {:.2f}\".format(multinb.score(xf_train,y_train)))\n",
    "print(\"Rendimiento de multinb sobre el conjunto de test: {:.2f}\".format(multinb.score(xf_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como el conjunto de datos no está balanceado y un clasificardor tonto que siempre predijese 'ham' conseguiría un score alto, utilizaremos además el método confusion_matrix del módulo metrics de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584, 8, 17, 230)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = y_test.values\n",
    "y_pred = multinb.predict(xf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = ['ham','spam']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la matriz de confusión obtenemos los valores de __verdaderos negativos__, __falsos positivos__, __falsos negativos__ y __verdaderos positivos__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste manual del parámetro de suavizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinb_alpha1 = MultinomialNB(alpha = 10).fit(xf_train,y_train)\n",
    "multinb_alpha2 = MultinomialNB(alpha = 3).fit(xf_train,y_train)\n",
    "multinb_alpha3 = MultinomialNB(alpha = 1.5).fit(xf_train,y_train)\n",
    "multinb_alpha4 = MultinomialNB(alpha = 0.9).fit(xf_train,y_train)\n",
    "multinb_alpha5 = MultinomialNB(alpha = 0.4).fit(xf_train,y_train)\n",
    "multinb_alpha6 = MultinomialNB(alpha = 0.1).fit(xf_train,y_train)\n",
    "multinb_alpha7 = MultinomialNB(alpha = 0.01).fit(xf_train,y_train)\n",
    "\n",
    "ya1_pred = multinb_alpha1.predict(xf_test)\n",
    "ya2_pred = multinb_alpha2.predict(xf_test)\n",
    "ya3_pred = multinb_alpha3.predict(xf_test)\n",
    "ya4_pred = multinb_alpha4.predict(xf_test)\n",
    "ya5_pred = multinb_alpha5.predict(xf_test)\n",
    "ya6_pred = multinb_alpha6.predict(xf_test)\n",
    "ya7_pred = multinb_alpha6.predict(xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1591    1   81  166] [82]\n",
      "[1589    3   30  217] [33]\n",
      "[1585    7   18  229] [25]\n",
      "[1583    9   16  231] [25]\n",
      "[1580   12   11  236] [23]\n",
      "[1581   11   11  236] [22]\n",
      "[1581   11   11  236] [22]\n"
     ]
    }
   ],
   "source": [
    "l_pred = [ya1_pred,ya2_pred,ya3_pred,ya4_pred,ya5_pred,ya6_pred,ya7_pred]\n",
    "con_list = [confusion_matrix(y_true, x, labels = ['ham','spam']).ravel() for x in l_pred]\n",
    "for x in con_list:\n",
    "    res = [x[1]+x[2]]\n",
    "    print(x,res)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_true, ya_pred, labels = ['ham','spam']).ravel()\n",
    "#(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obsrevar que el número de casos mal clasificados se reduce en conjunto al disminuir el parámetro alfa, y que en varias ocasiones se produce un desplazamiento de los casos mal clasificados entre los falsos positivos y los falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización con min_df y stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2 = CountVectorizer(min_df=50, stop_words=\"english\").fit(x_train)\n",
    "xf2_train = vect2.transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado un segundo vectorizador utilizando en este caso las opciones de **min_df**, que establece un número mínimo de paraiciones en el texto para considerar una palabra como relevante, y **stop_words**, que recibe el nombre de una lista  de palabras que eliminará por ser irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario original: 7053\n",
      "Número de términos en el vocabulario con stop words y min_df: 75\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario original: {}\".format(len(feature_names)))\n",
    "feature_names2 = vect2.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y min_df: {}\".format(len(feature_names2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos un nuevo clasificador utilizando el nuevo valor vectorizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572, 20, 59, 188)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinb2=MultinomialNB(alpha=1).fit(xf2_train,y_train)\n",
    "\n",
    "xf2_test = vect2.transform(x_test)\n",
    "y2_pred = multinb2.predict(xf2_test)\n",
    "y2_true = y_test.values\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y2_true, y2_pred, labels = ['ham','spam']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha comprobado que el valor máximo que se puede utilizar en **min_df** en este caso es **235**. Para dicho valor el clasificador no es capaz de reconocer los casos negativos demanera correcta y clasifica todo como positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1592, 0, 247, 0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect235 = CountVectorizer(min_df=235, stop_words=\"english\").fit(x_train)\n",
    "xf235_train = vect235.transform(x_train)\n",
    "multinb235=MultinomialNB(alpha=1).fit(xf235_train,y_train)\n",
    "\n",
    "xf235_test = vect235.transform(x_test)\n",
    "y235_pred = multinb235.predict(xf235_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y2_true, y235_pred, labels = ['ham','spam']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, por otro lado, el número para el que se ha observado el menor valor, de falsos negativos y falsos positivos es 1, de manera que no se toman en cuenta las palabras que sólo aparecen 1 vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581, 11, 15, 232)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect100 = CountVectorizer(min_df=1, stop_words=\"english\").fit(x_train)\n",
    "xf100_train = vect100.transform(x_train)\n",
    "multinb100=MultinomialNB(alpha=1).fit(xf100_train,y_train)\n",
    "\n",
    "xf100_test = vect100.transform(x_test)\n",
    "y100_pred = multinb100.predict(xf100_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y2_true, y100_pred, labels = ['ham','spam']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos la diferencia en los vocabularios de min_def = 235 y min_df = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario con stop words y min_df = 235: 1\n",
      "Número de términos en el vocabulario con stop words y min_df = 1: 6794\n"
     ]
    }
   ],
   "source": [
    "feature_names235 = vect235.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y min_df = 235: {}\".format(len(feature_names235)))\n",
    "feature_names100 = vect100.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y min_df = 1: {}\".format(len(feature_names100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comprobamos que ocurre si no utilizamos min_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581, 11, 15, 232)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectst = CountVectorizer(stop_words=\"english\").fit(x_train)\n",
    "xfst_train = vectst.transform(x_train)\n",
    "multinbst=MultinomialNB(alpha=1).fit(xfst_train,y_train)\n",
    "\n",
    "xfst_test = vectst.transform(x_test)\n",
    "yst_pred = multinbst.predict(xfst_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y2_true, yst_pred, labels = ['ham','spam']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario con stop words y min_df = 1: 6794\n",
      "Número de términos en el vocabulario con stop words y sin min_df: 6794\n"
     ]
    }
   ],
   "source": [
    "feature_names100 = vect100.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y min_df = 1: {}\".format(len(feature_names100)))\n",
    "feature_names_st = vectst.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y sin min_df: {}\".format(len(feature_names_st)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que, en nuestro caso, un mayor valor de min_df aumenta la cantidad de casos clasificados de manera errónea, y que para el valor que se han observado mejores resultados, que es 1, se obtienen los mismos resultados y el mismo tamaño de vocabulario que si optamos por no utilizar el parámetro min_df y sólo usar **stop_words**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
